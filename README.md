Usage:



Cost calculation:
Prices are for the newest model without Batches. 
For 1 million prompt tokens, OpenAI charges 5$. For every million tokens that ChatGPT produces they charge 15$. This means, that the total price cannot be calculated beforehand. 
However, since the answers will probably stay short (yes, no, a percentage) a price can be estimated. 
When creating a population, ChatGPT is prompted 120 tokens and will output 10-15 tokens.
Creating the subject is around 85 tokens
One Headline is between 10-20 tokens (estimated 15).
The 3 questions are 90 tokens. 
For the answers I estimated a maximum of 15 Tokens (~8 words) per answer. 

Calculating with a generated population of 1000 and 100 questions the price would be:
Request prices:                                              
  Creation of every person: 1000*(120+85)   = 205 000                    
  Prompting the questions: 1000*100*(15+90) = 10.5*10^6       
  Total                                     = 10.7*10^6                   
  Total price                               = 53.50$ 
 
  Output prices:
  
    Creation of every person:   1000*15     = 15 000
    Prompting the questions:    1000*100*15 = 1.5*10^6
    Total                                   = 1.5*10^6
    Total price                             = 22.50$
  
  
  Total cost  =76$                               
